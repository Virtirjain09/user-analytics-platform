# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16TCUVjMRJfc3UUHfXg4r0soYiV4Yz_hc
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.sequence import pad_sequences

# =====================================================================
# FUNCTION DEFINITIONS
# =====================================================================

def calculate_funnel_data(df, funnel_steps):
    """Calculates user counts at each step of a defined funnel."""
    funnel_data = []
    # Start with all users who completed the first step
    previous_step_users = set(df[df['event_name'] == funnel_steps[0]]['user_id'].unique())
    funnel_data.append({'step': funnel_steps[0], 'user_count': len(previous_step_users)})

    for i in range(1, len(funnel_steps)):
        current_step_users = set(df[df['event_name'] == funnel_steps[i]]['user_id'].unique())
        # Users must have also completed the previous steps
        retained_users = previous_step_users.intersection(current_step_users)
        funnel_data.append({'step': funnel_steps[i], 'user_count': len(retained_users)})
        previous_step_users = retained_users

    return pd.DataFrame(funnel_data)

def calculate_retention_cohorts(df):
    """Calculates monthly retention cohorts."""
    df_copy = df.copy()
    df_copy['timestamp'] = pd.to_datetime(df_copy['timestamp'])

    # Get signup month for each user
    df_signup = df_copy[df_copy['event_name'] == 'signed_up'].copy()
    df_signup['signup_month'] = df_signup['timestamp'].dt.to_period('M')
    user_signup_month = df_signup[['user_id', 'signup_month']].drop_duplicates()

    # Merge signup month back to all events
    df_merged = pd.merge(df_copy, user_signup_month, on='user_id')

    # Calculate activity month for each event
    df_merged['activity_month'] = df_merged['timestamp'].dt.to_period('M')

    # Calculate month number since signup
    df_merged['month_number'] = (df_merged['activity_month'] - df_merged['signup_month']).apply(lambda x: x.n)

    # Pivot to create the cohort table
    cohort_data = df_merged.groupby(['signup_month', 'month_number'])['user_id'].nunique().reset_index()
    cohort_pivot = cohort_data.pivot_table(index='signup_month', columns='month_number', values='user_id')

    # Calculate retention percentage
    cohort_size = cohort_pivot.iloc[:, 0]
    retention_matrix = cohort_pivot.divide(cohort_size, axis=0)
    retention_matrix.index = retention_matrix.index.astype(str)
    return retention_matrix

# =====================================================================
# DATA & MODEL LOADING (Corrected Order)
# =====================================================================

# --- Load Data ---
@st.cache_data
def load_data():
    df = pd.read_csv('data/user_events.csv')
    df['timestamp'] = pd.to_datetime(df['timestamp'])
    return df

# --- Load Model ---
@st.cache_resource
def load_keras_model():
    return load_model('models/churn_lstm_model.keras')

# **Load data and model right after defining the functions**
df = load_data()
model = load_keras_model()

# **Create the event mapping using the now-defined 'df'**
# This mapping must be identical to the one in train_model.py
temp_event_mapping = {event: i for i, event in enumerate(df['event_name'].unique())}
# Ensure the padding value from training (-1) isn't a valid event_id
if -1 in temp_event_mapping.values():
    event_mapping = {event: i + 1 for i, event in enumerate(df['event_name'].unique())}
    padding_value = 0
else:
    event_mapping = temp_event_mapping
    padding_value = -1


# =====================================================================
# STREAMLIT APP LAYOUT
# =====================================================================

st.set_page_config(layout="wide")
st.title(" User Behavior Analytics Platform")

# --- Sidebar ---
st.sidebar.header("Controls")
st.sidebar.info(f"Loaded {len(df)} events for {df['user_id'].nunique()} users.")

# --- Funnel Analysis Section ---
st.header("Funnel Analysis")
st.markdown("Identifies drop-off points in the user journey.")

funnel_steps = ['signed_up', 'viewed_dashboard', 'created_project', 'invited_teammate', 'upgraded_plan']
selected_funnel_steps = st.multiselect("Select funnel steps:", options=funnel_steps, default=funnel_steps)

if len(selected_funnel_steps) > 1:
    funnel_df = calculate_funnel_data(df, selected_funnel_steps)

    fig_funnel = go.Figure(go.Funnel(
        y = funnel_df['step'],
        x = funnel_df['user_count'],
        textinfo = "value+percent initial"
    ))
    fig_funnel.update_layout(title="User Conversion Funnel")
    st.plotly_chart(fig_funnel, use_container_width=True)
else:
    st.warning("Please select at least two funnel steps.")

st.divider()

# --- Retention Cohort Section ---
st.header("Monthly Retention Cohorts")
st.markdown("Tracks the percentage of users who return in the months following their sign-up.")

retention_matrix = calculate_retention_cohorts(df)
fig_cohort = px.imshow(retention_matrix, text_auto=".0%", aspect="auto", color_continuous_scale='Blues')
fig_cohort.update_layout(
    title="Monthly User Retention",
    xaxis_title="Months Since Signup",
    yaxis_title="Signup Cohort"
)
st.plotly_chart(fig_cohort, use_container_width=True)

st.divider()

# --- Churn Prediction Section ---
st.header("Live Churn Prediction")
st.markdown("Select a user to predict their likelihood of churning based on their event history.")

user_list = sorted(df['user_id'].unique())
selected_user = st.selectbox("Select a User ID:", options=user_list)

if st.button("Predict Churn"):
    # 1. Get user's event sequence
    user_sequence_events = df[df['user_id'] == selected_user].sort_values('timestamp')['event_name']
    user_sequence_ids = [event_mapping.get(event) for event in user_sequence_events]

    # 2. Preprocess the sequence
    padded_sequence = pad_sequences([user_sequence_ids], maxlen=50, padding='post', truncating='post', value=padding_value)

    # 3. Reshape for the model
    reshaped_sequence = padded_sequence.reshape(1, 50, 1)

    # 4. Predict
    prediction_proba = model.predict(reshaped_sequence)[0][0]

    # 5. Display result
    st.subheader(f"Prediction for User {selected_user}")
    if prediction_proba > 0.5:
        st.error(f"High Churn Risk: {prediction_proba:.2%}", icon="ðŸš¨")
    else:
        st.success(f"Low Churn Risk: {prediction_proba:.2%}", icon="âœ…")

    with st.expander("View User's Event History"):
        st.dataframe(df[df['user_id'] == selected_user][['event_name', 'timestamp']].sort_values('timestamp', ascending=False))